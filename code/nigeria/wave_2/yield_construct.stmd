% statamarkdown intro
% emil keetui 
% `s c(current_date)`

# Generating Maize Yield (kg/ha) in Nigeria General Household Survey, Panel 2012-2013, Wave 2

This is a guide to generating the maize yield variable (kilograms of maize per hectare) from the Nigeria General Household Survey, Panel 2012-2013, Wave 2 (Survey ID Number: NGA_2012_GHSP-W2_v02_M). The basic steps we take here are the same steps you could take to generate yield variables in other waves and for other crops. This guide includes the stata commands and the stata output but following the steps on your own is helpful. To use the same files we use in this guide download the Nigeria General Household Survey, Panel 2012-2013, Wave 2 (Survey ID Number: NGA_2012_GHSP-W2_v02_M) from the World Bank website's Central Data catalog - instructions are given below on how to find and download the files from the World Bank website.

# Instructions on Downloading the Data from the World Bank Website

To access the data from the World Bank website go the Central data catalog on the world bank website, then find the "filter by collection on the left hand side of the webpage" and select checkbox for the Living Standards Measurement Survey (LSMS) filter. LSMS surveys are catergorized alphabetically by country names and then chronologically by the year and wave of the survey. Browse the pages until you find the General Household Survey, Panel 2012-2013, Wave 2 for Nigeria, 2012-2013, select that. Under the heading there are four tabs called STUDY DESCRIPTION, DOCUMENTATION, DATA DESCRIPTION, and GET MICRODATA, click on the GET MICRODATA tab. You will be asked to log in with World Bank user profile, which if you do not already have a profile you will be redirected to creat one, follow the instructions to create a profile and then repeat the steps to find the General Household Survey, Panel 2012-2013, Wave 2 for Nigeria. If you already have a profile you will be redirected to a form submission page where you must write in the box provided a brief description of the research project that will use the data, which once you have submitted you will be redirected to the data files that are available for download in SPSS, CSV, and STATA formats. To follow this guide select the STATA format. Once the download is complete open the compressed zip file "NGA_2012_GHSP-W2_v02_M_STATA", and navigate to Post Harvest Wave 2, Agriculture, and select the file sect3a_harvestw2.dta. Keep the raw data files and the cleaned data files separate so it is a good idea to duplicate sect3a_harvestw2 in another folder where you will work on it from there, this way you can always refer to the original raw data file in the original NGA_2012_GHSP-W2_v02_M_STATA file if you need to. The path we save the raw data is: "G:\My Drive\lsms_data_product\data demonstration\Nigeria\wave_1\raw data\, you should use a file convention that suits you.



To get started tell Stata to "use" the file "secta3_harvestw2.dta" and include the location of where the to find the file on your computer. Ours is kept on the Google drive in a series of folders within folders starting with "lsms_data_product" and ending with "raw data". Add a comma and then a "clear", this clears any data already in stata.

```{s}

use "$root/wave_2/raw/secta3_harvestw2.dta", clear 

```

This data was collected after the main harvest and is at the crop level, meaning respondents were asked questions about each crop they planted, such as how much they harvested, if it was sold and how much it was worth, the plot it was grown on, etc. In Stata you can see data by going to the tool bar and selecting Data,Data Editor, and Data Editor (Browse). Browse shows you the data in a spread sheet, each column is a variable and each row is a crop because our data is at the crop level. Exit the Browser and go to the box where you type in commands, or the command line. Look at what kind of crops by asking stata to *tabulate* ***cropcode***. 

```{s}
tabulate cropcode
```

Note that the names of the crops are displayed as words in the output table but they are stored as integers in the data. Maize is encoded as 1080 in ***cropcode***.

Restrict our observations to a single harvest season. Although this data was collected after the main harvest some households might not have harvested when the enumerators conducted their surveys, so remove those households from the sample that did not harvest because it was not harvest season or they delayed their harvest and will harvest in another season. But keep the households that did not harvest because their crop failed for one reason or another. We can identify households that did not harvest this season for a reason besides crop failure using ***sa3q3*** which records the response to the question "Have you harvested any of the following crops since the last interview?" The variable is coded to be matched to the survey instrument if you want to see how the question was actually given to respondents. But to make the variable clearer for ourselves rename ***sa3q3** to ***harvest***:

```{s}
	rename sa3q3 harvest
```

Note, ***sa3q4*** records the reason that a household failed to harvest. Use the *tabulate* command for stata to list the reasons households failed to harvest.

```{s}
	tab sa3q4
```

Stata displays the reasons for failing to harvest as whole sentences in the output but each reason is stored in the data as integers and when we write code we have to use the integer. Find the integer code of a response using the data browser and find ***sa3q4*** and then select cells. The cells still appear to show words for each reason but select a cell and notice that the text bar above the cell matrix displays an integer - this integer is what we write in our code. Command Stata to "sort sa3q4" to put the responses in ascending order so its easier to find the response you are looking for.

```{s}
	sort sa3q4
```

Identify the integer code for not harvesting because it was "not harvest season", "delayed harvest" and "other specify". 

Drop observations if they did not harvest because it was not harvest season, the harvest was delayed, and other non-specified reasons which should be encoded as 9, 10, and 11 respectively. We can combine these qualifiers into a single command using an "or" statement, note that stata reads the vertical line symbol “|” as an “or” statement.

```{s}
	drop if 		sa3q4 == 9 | sa3q4 == 10 | sa3q4 == 11
```
	
The remaining households that did not harvest may have a missing harvest quantity and value. Make sure the remaining households that did not harvest have a 0 for the quantity and value of their harvest. Quantity is ***sa3q6a1*** and value is ***sa3q18***.

```{s}
	replace			sa3q6a1 = 0 if sa3q6a1 == . & sa3q4 < 9
	replace			sa3q18  = 0 if sa3q18  == . & sa3q4 < 9
```

Many respondents in all three waves of the Nigeria survey gave the weights of their harvests in local units and not in standardized units. We ultimately want to produce a variable that is the maize yield measured in kilograms of maize per hectare and we will need to convert the non-standard units into kilograms. Rename ***sa3q6a2*** to ***nscode***. Note that harvest units have been encoded just like the reason for not harvesting variable.

```{s}
	rename 			sa3q6a2 nscode
```

# Converting harvest weights to Kilograms

We will convert non-standard units into kilograms by merging the current dataset with harvconv_wave_2.dta which contains a numerical conversion factor to convert each crop and non-standard measurement to the equivalent measurement in kilograms. The non-standard units are a challenge to convert because some of the units are measured by volume such wheelbarrows and sacks. Sacks and wheelbarrows are not standard volumes either and they vary by the brand of the sack or wheelbarrow and possibly by region and the weight of a wheelbarrow of melons is not the same as the weight of a wheelbarrow of maize and conversion will be approximate and not perfect. 
Before merging keep in mind all crops of the same type when measured with the same units will share the same conversion factor and in data science matching more than one oberservation from the main dataset to one observation in the merging dataset is called a many to one merge. Keep ph_secta3.dta open and merge harvconv_wave_2.dta on ***cropcode*** and ***nscode*** and specify the type of merge as many to one (m:1).

```{s}
 merge 			m:1 cropcode nscode using "$root/wave_2/raw/w2agnsconversion.dta"
```

After a merge command Stata automatically produces a variable called ***_merge*** that it is encoded as ***_merge***==3 if an observation from the "master" (the main file secta3_harvestw2.dga) was matched to an observation from the "using" (the conversion file). ***_merge***==1 if an observation from the master file was unable to be matched to an observation in the using, this means a crop is measured by a unit we do not have a conversion for. And ***_merge***==2 if an observation from the using file was not matched to the master, this means the using file contained a crop and a unit of measurement that is not present in the main data so we don't need it. Drop the observations we don't need.

```{s}
	drop if			_merge == 2
```

Lets address the observations that are missing a conversion. A likely culprit for an unmatched observation is a missing ***nscode*** or ***cropcode***. Check for missing ***nscode*** by asking stata to count the observations with missing ***nscode***(==.) and a ***_merge***==1.

```{s}
	count if 		nscode==. & _merge == 1
```

Drop those observations that are missing a ***nscode*** because we can't convert those observations without the unit.

```{s}
	drop if 		nscode == . & _merge == 1
```

An observation can go unmatched if the conversion file did not have a conversion for a unit in the master. Tabulate ***nscode*** for the unmatched observations to check what was omitted.

```{s}
	tab 			nscode if _merge == 1
```

If an umatched observation is already in kilograms, or grams or a unit you know how to convert to kiligrams then we can keep those observations. We need to replace the ***conversion*** those observations with the conversion factor. For example replace the missing conversion for kilograms to 1. ***nscode*** is encoded and we must sort the data on ***nscode*** and look up the code for kilograms in the data browser. Kilograms are encoded 1. 

```{s}
	replace			conversion = 1 if conversion == . & nscode==1
```

We drop an observation if the harvest unit cannot be converted. Note in Stata “!=” is equivalent to the statement “not equal to”.

```{s}
	drop if			_merge == 1 & nscode != 1
```

We can now drop the ***_merge*** variable.

```{s}
	drop 			_merge
```

Check for missing ***conversion***.

```{s}
	count if		conversion == .
```
	
Generate ***harv_kg*** that is harvest weights in kilograms by multiplying the conversion factors with the nonstandard weights.

```{s}
	generate			harv_kg = sa3q6a1*conversion
```
	
Several types of maize varieties were grown and we want to make it easier by recoding them all as one type of maize. Sort ***cropcode*** with the command "sort ***cropcode***" and then look in the data browser to find the codes for the different types of maize. Note that all types of maize are encoded between 1080 and 1084 and generic maize is 1080. Replace all maize with 1080.

```{s}
	replace			cropcode = 1080 if cropcode > 1079 & cropcode < 1084
```

Make a maize harvest variable called ***mz_hrv*** for all the maize crop weights. All non-maize observations will be missing in the variable ***mz_hrv***.

```{s}
	gen 			mz_hrv = harv_kg 	if 	cropcode == 1080
	lab var			mz_hrv "Quantity of maize harvested (kg)"
```
Make a binary variable ***mz_damaged*** to identify a maize crop that experienced crop failure or substantial damage and have ***mz_hrv***==0. 

```{s}
	gen			mz_damaged = 1	if  cropcode == 1080  & mz_hrv == 0
	replace 			mz_damaged = 0 	if mz_hrv > 0
```

# Imputing far outliers

"Summarize" command, or "sum" for short, will tell us the mean, maximum, minimum and other key statistics on a numerical variable. Summarize ***mz_hrv*** and note the distribution of the data and the maximum values. 

```{s}
	sum				mz_hrv, detail
```

Compare the summary statistics to reliable crop yield data from the area of study and determine if our data appears at first glance to be reasonable in the context of the region we are studying. 


You may use your discretion in choosing how to identify outliers and be consistent to your identification throughout your data cleaning process. We consider an outlier to be an observation that is 3 standard deviations above the mean. The stata code for 3 standard deviations above the mean is `r(p50)' + (3*`r(sd)') where `r(p50)' is the mean and `r(sd)' is the standard deviation and 3*`r(sd)' is 3 times the standard deviation. Replace observersations that are outside of the 3 standard deviations as missing because they are more likely to be errors of recall or recording.

```{s}
replace			mz_hrv = .  	if 	mz_hrv > `r(p50)' + (3*`r(sd)')
```

We want to replace the now missing values using imputation which is simulating data using the behavior of the rest of the data. See Kilic, et al 2017 for background on using imputation to simulate missing data. Impute the missing maize harvest values using Predictive Mean Matching technique (PMM). We set out the steps taken in pmm imputation to provide context for the impute commands in Stata. 

In summary firstly least squares estimates multiple estimates of the dependent variable on variables we think will be relevant to the harvest quantity such as location. secondly, the estimate is matched to 5 existing observations that are close wihtin a distance measure. thirdly, randomly one of the 5 close observations are chosen to replace the missing observation. Then store the imputations and reepeat steps 1-3 several times. Finally, take the mean of the stored imputations and replace the missing with mean. 

"Mi" (multiple imputation) is the Stata command for imputing. Set the data structure as wide or long. Our data is wide because a unique observation is identified by a unique row.

```{s}
	mi set 			wide 
```
Clear any time series settings you may have in place or else the time series will interfere with the linear regression we run later.

```{s}
	mi xtset		, clear 	
```
	
Register ***mz_hrv*** as the variable we will be imputing.

```{s}
	mi register		imputed mz_hrv 
```

Sort the data to ensure reproducibility. Sorting the data can be done at any stage before the actual imputation. Data is uniquely identified by ***hhid*** ***plotid*** ***cropid***. 

```{s}
	sort			hhid plotid cropid 

	mi impute pmm mz_hrv i.state if cropcode == 1080, add(1) rseed(245780) noisily dots force knn(5) bootstrap
```

Use predictive mean matching (pmm) to impute the data, the regression’s dependent variable is ***mz_hrv*** and the independent variable is ***i.state*** (a dummy for each state). Set option "force" to enable the regression to run even if an error occurs; "knn(#)" determines the number of non-missing ***mz_hrv*** observations to match to the estimate, for example we choose to match to the nearest 5 observations; "bootstrap" requests Stata sample the data with replacement and regress on the created random sample; "rseed(#)" specifies the random number seed used to create the sample. 

Declare the imputing to be over:

```{s}
	mi 				unset	
```
	
Use command "tabstat" to compare the imputed maize harvest variable (***mz_hrv_1_***) to the original maize harvest variable (***mz_hrv***). The "tabstat" command compares two or more variables on the parameters of our choice, for example we want to see the number of observations in each variable “n”, the mean “mean”, and the minimum and the maximum, “min” and “max”. "Tabstat" is a versatile command and the researcher can choose to report the statistics of their choice. 

```{s}
	tabstat			mz_hrv mz_hrv_1_ if cropcode == 1080, by(mi_miss) ///
						statistics(n mean min max) columns(statistics) ///
						longstub format(%9.3g) 
```

If after imputation the data resembles the known distribution of maize yields in Nigeria then replace the original maize harvest (***mz_hrv***) with the imputed maize harvest (***mz_hrv_1***) and drop the imputed maize harvest. If the results are still not resembling known distributions then you can start by reducing the distribution you tolerate and replace more missing values based on the new outlier boundaries, then impute the missing data. We continue.

```{s}
	replace			mz_hrv = mz_hrv_1_  if cropcode == 1080
	drop			mz_hrv_1_
```

Make an identifier variable ***cropplot*** that uniquely identifies a crop by the crop’s name, the plot it was grown on, and the household that grew it.  The Stata command "isid" checks a variable or list of variables uniquely identify our observations. Stata will not display a result after the isid command if the variables do uniquely identify our observations but will display an error if the variables do not uniquely our observations. 

```{s}
	isid			hhid plotid cropid
	sort			hhid plotid cropid
	egen			cropplot_id = group(hhid plotid cropid)
	lab var			cropplot_id "unique crop-plot identifier"
```

Save the file we have been working on and save it in a seperate place to the orignal raw data.

```{s}
	save "$root/wave_2/refined/secta3_harvestw2.dta", replace	
```

# Land area plot size

From the same wave open the plot characteristics dataset "sect11a1_plantingw2.dta" in the post planting file found in the file you downloaded from the microdata, NGA_2012_GHSP-W2_v02_M_STATA. 

```{s}
	use				"$root/wave_2/raw/sect11a1_plantingw2.dta", clear
```

The data in "sect11a1_plantingw2.dta" is organized at the plot level and we will eventually match each plot from this file to the crop which grew in the plot from the "secta3_harvestw2.dta" file. 

Confirm the data is uniquely identified by a plot id number and a household id number (hhid) and that no household has two plots with the same id or two households have the same id. 

```{s}
	sort 			hhid plotid
	isid 			hhid plotid
```
If household id and plot id do not uniquely identify all observations then inspect the duplicate observations using the Stata command "duplicates report". You should delete all but one of the perfect duplicates i.e. observations that share all information.

# Cleaning Plot Size

Begin cleaning the data on plot size. Plot area is measured by a self-reported variable (***s11aq4a***) which is the respondents recollection of the size of the plots. The self-reported land units are not all hecatres so a plot unit variable ***s11aq4b*** encodes the units, there are 7 units encoded by integers 1-7 browse them in the usual way we browse encoded variables and sorting the variable and looking it up in the databrowser. And we will use a conversion file called "land-conversion.dta" later to convert the plots to hectares. The variables in "land-conversion.dta" are conversion factors converting each of the non-standard area units (ridges, heaps, plots, stands, square meters, acres, and hectares) to hectares. Plot size is also measured by a GPS measured plot area (***s11aq4c***) taken by an enumerator with a handheld GPS and is in square meters. Generate descriptively named variables which contain the same data as the self-reported plot size and GPS plot size. 

```{s}
	rename 			s11aq4b plot_unit
	lab 	var		plot_unit "self reported unit of measure"

	
	gen 			plot_size_SR = s11aq4a
	lab	var			plot_size_SR "self reported size of plot, not standardized"
	
	gen 			plot_size_GPS = s11aq4c
	lab 	var		plot_size_GPS 	"GPS plot size in sq. meters"
```

Now take the "land-conversion.dta" file from the zip "NGA_2012_GHSP-W2_v02_M_STATA". Use the merge command to merge "land-conversion.dta" to the master "sect11a1_plantingw2.dta". ***Zone*** will be used to match the master and using because local units differ by zone, Stata will match an observation in the master file with an observation in the using file when the observations share a zone. Specify a many to one merge (m:1) to authorize Stata to match the same observation from the using to multiple observations in the master file. 

```{s}
	merge 			m:1 	zone using "$root/wave_2/refined/land-conversion.dta"
```

Keep observations that merged and where ***_merge***=3 and drop observations where ***_merge***=2. The Stata command "keep" will keep all observations that meet a condition and drop all observations that do not meet the condition.

```{s}
	keep 			if 		_merge == 3
	drop 			_merge
```

We can now convert the self-reported plot size into hectares. Make a new variable ***plot_size_hec_SR*** for self-reported plot size and temporarily make the entries in that variable missing, we will replace them in a moment. 

```{s}
	gen 			plot_size_hec_SR = .
	lab var			plot_size_hec_SR 	"SR plot size converted to hectares"
```

 Convert the measurements not given in hectares into hectares by multiplying the appropriate conversion variable by the farmer’s self-reported plot measurement and replace the missing observations in ***plot_size_hec_SR*** with the converted self-reported plot size. 

The steps to convert and replace ridges with hectares is a follows:

```{s}
	replace 		plot_size_hec_SR = plot_size_SR*ridgecon	if plot_unit == 2
```

For converting heaps:

```{s}
	replace 		plot_size_hec_SR = plot_size_SR*heapcon	if plot_unit == 1
```

For converting stands:

```{s}
	replace 		plot_size_hec_SR = plot_size_SR*standcon	if plot_unit == 3
```

For converting plots:

```{s}
	replace 		plot_size_hec_SR = plot_size_SR*plotcon	if plot_unit == 4
```
For converting acres:

```{s}
	replace 		plot_size_hec_SR = plot_size_SR*acrecon	if plot_unit == 5
```
For converting square meters:
	
```{s}
	replace 		plot_size_hec_SR = plot_size_SR*sqmcon	if plot_unit == 7
```
For converting hectares we do not need a conversion:

```{s}
	replace 		plot_size_hec_SR = plot_size_SR			if plot_unit == 6
```
All observations should have been converted. Count the missing observations to make sure none were left out.

```{s}
	count			if plot_size_hec_SR == . 
```

We will have to drop other units that did not have conversion factors in the conversion file.
	
Recall, ***plot_size_GPS*** is in square meters and need to be converted into hectares and we will convert it to hectares by multiplying ***plot_size_GPS*** with the square meter conversion factor (***sqmcon***). Make a new variable for the plot area measured by GPS (***plot_size_hec_GPS***).

```{s}
	gen 			plot_size_hec_GPS = .
	lab	var			plot_size_hec_GPS "GPS measured area of plot in hectares"
```

Convert them in the same way we converted the ***plot_size_hec_SR***.

```{s}
	replace 		plot_size_hec_GPS = plot_size_GPS*sqmcon
	
	count 			if plot_size_hec_GPS == .  
```

Self-reported plot size and GPS plot size measure the same thing, and should both be used when they are both reliable. The correlation between self-reported and GPS measurements will be used to establish how closely they resemble each other and if self-reported plot area is reliable.  In Stata the pwcorr command calculates and displays the correlation between two variables. 

```{s}
	pwcorr 			plot_size_hec_SR plot_size_hec_GPS
```

Do they possess a strong or weak correlation?

# plot size

Exame the correlation between ***plot_size_hec_SR*** and ***plot_size_hec_GPS*** within three standard deviations of the mean of ***plot_size_hec_GPS***. We set the comparison boundary so were limiting observations that are either within 3 standard deviations or only outside of 3 standard deviations. The boundary is set by a pwcorr command then the two variables we want examine, followed by an if statement of a boundary with the option "inrange()". Within three standard deviations of the mean requires setting an upper bound, which is `r(p50)' + (3*`r(sd)') where `r(p50)' is the mean and `r(sd)' is the standard deviation and 3*`r(sd)' is three times the standard deviation, and a lower bound which is `r(p50)' - (3*`r(sd)') where `r(p50)' is the mean and `r(sd)' is the standard deviation and 3*`r(sd)' is three times the standard deviation. Importantly you must run a "summarize" command so that stata can store the distribution statistics such as mean and standard deviation which you use later in the code.

```{s}

	sum 		plot_size_hec_GPS, detail
	pwcorr 			plot_size_hec_SR plot_size_hec_GPS if ///
				inrange(plot_size_hec_GPS,`r(p50)'-(3*`r(sd)'),`r(p50)'+ (3*`r(sd)'))
```

What is the strength of the correlation?

Correlate observations within three standard deviations of the mean of ***plot_size_hec_SR*** and ***plot_size_hec_GPS***.

```{s}

	sum 			plot_size_hec_GPS, detail
	sum 			plot_size_hec_SR, detail
	pwcorr 			plot_size_hec_SR plot_size_hec_GPS if ///
				inrange(plot_size_hec_GPS,`r(p50)'- (3*`r(sd)'),`r(p50)'+ (3*`r(sd)')) & ///
				inrange(plot_size_hec_SR,`r(p50)'- (3*`r(sd)'),`r(p50)'+ (3*`r(sd)'))
```

Check the correlation between ***plot_size_hec_SR*** and ***plot_size_hec_GPS*** outside of 3 standard deviations of the mean and for that we must know what the larger values ***plot_size_hec_SR*** and ***plot_size_hec_GPS*** take. A "summarize" command performed on ***plot_size_hec_SR*** and ***plot_size_hec_GPS*** will report the largest values in both variables. In the General Household Survey, Panel 2012-2013, Wave 2 for Nigeria we find that 3 hectares is close to the largest plots measured in the sample.

```{s}
	pwcorr 			plot_size_hec_GPS plot_size_hec_SR 	if 	plot_size_hec_GPS > 3 
```
Examine the correlation between plot_size_hec_SR and plot_size_hec_GPS among smaller plots. In the General Household Survey, Panel 2012-2013, Wave 2 for Nigeria we find that 0.01 hectares was close to the smallest plots measured in the sample.

```{s}
	pwcorr 		plot_size_hec_GPS plot_size_hec_SR 	if 	plot_size_hec_GPS < 0.01
```

The researcher's judgement should be used to determine if the plot size responses are reasonable. 

```{s}
	sum 			plot_size_hec_GPS
	sum 			plot_size_hec_SR
```
We will use the GPS plotsize, ***plot_size_hec_GPS*** because we find that GPS plot area is more reliable than self-reported measures of plot ***size plot_size_hec_SR***.

Save the file we have been working in "sect11a1_plantingw2.dta" in a separate location to the raw file.

```{s}
	save "$root/wave_2/refined/sect11a1_plantingw2.dta", replace	
```
# Maize Yield

 Now open "secta3_harvestw2.dta" and merge the crop data with the plot data. We want to use "secta3_harvestw2.dta" as the master file because all crops were grown on plots but not all plots were used to grow crops. 

```{s}
	use				"$root/wave_2/refined/secta3_harvestw2.dta", clear 
```
	
We made an id variable ***cropplot_id*** when working on "sect3a_harvestw2.dta" confirm that it uniquely identifies each observation with the "isid" command. Recall that when a variable uniquely identifies each observation "isid" will not display a result and when a variable fails to uniquely identify the observations "isid" will display an error.

```{s}
	isid			cropplot_id
```
	
Merge in plot size data, "sect11a1_plantingw2.dta", and merge on ***hhid*** and ***plotid***. Multiple crops can be grown on one plot and multiple crops may be matched to the same plot, set the matching option to many to one (m:1).

```{s}
	merge 			m:1 hhid plotid using "$root/wave_2/refined/sect11a1_plantingw2.dta"
```
	
Drop observations that did not match. Observations that did not match are plots that we cannot match to a crop or crops we cannot match to a plot and the only way to identify where a crop was grown or what crop was grown on a plot is the "merge" command we just executed so we cannot do much more. Recall all successful matches have ***_merge***=3. Note “!=” is equivalent to a "not equal" statement so let's use != to drop all observations not equal to 3.

```{s}
	drop			if _merge != 3
```
	
The data is currently at the crop level, "collapse" the data to the plot level. Before we collapse note currently there may be multiple entries for a single plot because the same plot may have matched with multiple crops and we want to condense multiple crop entries into a single entry that summarizes all the crop data for one plot. So we have to decide how to agglomerate multiple crops, in this case adding them together is best option. So we write the option (Sum) after "collapse" to get the total weight of maize harvested from the plot. Take the maximum value of the plot size, plot duplicates have the same size. ***Mz_damaged*** is a binary variable and the maximum value is 1 so agglomerating it with a max maintains the binary. 

```{s}
	collapse (sum)	 mz_hrv  (max) plot_size_hec_GPS mz_damaged, by(hhid plotid zone state lga sector ea)
```

Replace non-maize harvest values as missing.

```{s}
	tab			mz_damaged, missing
	replace			mz_hrv = . if mz_damaged == . & mz_hrv == 0		
	drop 			mz_damaged
```

Generate a variable for the area of land maize was grown on.

```{s}
	gen			mz_lnd = plot_size_hec_GPS	if mz_hrv != .
```

Construct maize yield (kg/ha).

```{s}
	gen			mz_yld = mz_hrv / mz_lnd, after(mz_hrv)
	lab var			mz_yld	"maize yield (kg/ha)"
```

Save the file.

```{s}
	save "$root/wave_2/refined/secta3_harvestw2.dta", replace	
```

	
# Citations

Kilic, T., Zezza, A., Carletto, C., & Savastano, S. (2017). Missing (ness) in action: selectivity bias in GPS-based land area measurements. World Development, 92, 143-157.

