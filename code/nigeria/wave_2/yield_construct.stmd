% Generating Maize Yield (kg/ha) in Nigeria General Household Survey, Panel 2012-2013, Wave 2
% Emil Kee-Tui 
% `s c(current_date)`

This is a guide to generating the maize yield variable (kilograms of maize per hectare) from the Nigeria General Household Survey, Panel 2012-2013, Wave 2 (Survey ID Number: NGA_2012_GHSP-W2_v02_M). The basic steps we take here are the same steps you could take to generate yield variables in other waves and for other crops. This guide includes the stata commands and the stata output but following the steps on your own is helpful. To use the same files we use in this guide download the Nigeria General Household Survey, Panel 2012-2013, Wave 2 (Survey ID Number: NGA_2012_GHSP-W2_v02_M) from the World Bank website's Central Data catalog - instructions are given below on how to find and download the files from the World Bank website.

# Instructions on Downloading the Data from the World Bank Website

To access the data from the World Bank website go the Central data catalog on the world bank website, then find the "filter by collection on the left hand side of the webpage" and select checkbox for the Living Standards Measurement Survey (LSMS) filter. LSMS surveys are catergorized alphabetically by country names and then chronologically by the year and wave of the survey. Browse the pages until you find the General Household Survey, Panel 2012-2013, Wave 2 for Nigeria, 2012-2013, select that. Under the heading there are four tabs called STUDY DESCRIPTION, DOCUMENTATION, DATA DESCRIPTION, and GET MICRODATA, click on the GET MICRODATA tab. You will be asked to log in with World Bank user profile, which if you do not already have a profile you will be redirected to creat one, follow the instructions to create a profile and then repeat the steps to find the General Household Survey, Panel 2012-2013, Wave 2 for Nigeria. If you already have a profile you will be redirected to a form submission page where you must write in the box provided a brief description of the research project that will use the data, which once you have submitted you will be redirected to the data files that are available for download in SPSS, CSV, and STATA formats. To follow this guide select the STATA format. Once the download is complete open the compressed zip file "NGA_2012_GHSP-W2_v02_M_STATA", and navigate to Post Harvest Wave 2, Agriculture, and select the file sect3a_harvestw2.dta. Keep the raw data files and the cleaned data files separate so it is a good idea to duplicate sect3a_harvestw2 in another folder where you will work on it from there, this way you can always refer to the original raw data file in the original NGA_2012_GHSP-W2_v02_M_STATA file if you need to.

```{s}

use "$root/wave_2/raw/secta3_harvestw2.dta", clear 

```

This data was collected after the main harvest and is at the crop level, meaning respondents were asked questions about each crop they planted, such as how much they harvested, if it was sold and how much it was worth, the plot it was grown on, etc.

There are many different types of crops in this file, but we only need maize. `tab` will display the different types of crops.

We have used the `quietly` command to suppress stata from displaying output. You do not have to include the quietly command. We have included it to make the guide more user friendly and not filled with stata output.

```{s}
quietly tabulate cropcode
```

Note that the names of the crops are displayed as words in the output table but they are stored as integers in the data. Maize is encoded as 1080 in **cropcode**.

We want to restrict our observations to a single harvest season. Although this data was collected after the main harvest some households might not have harvested when the enumerators conducted their surveys. Remove those households from the sample that did not harvest because it was not harvest season or they delayed their harvest and will harvest in another season. But keep the households that did not harvest because their crop failed for one reason or another. We can identify households that did not harvest this season for a reason besides crop failure using **sa3q3** which records the response to the question "Have you harvested any of the following crops since the last interview?" The variable is coded to be matched to the survey instrument if you want to see how the question was actually given to respondents you can check the survey instrument. But to make the variable clearer for ourselves rename **sa3q3** to **harvest**:

```{s}
	rename sa3q3 harvest
```

Note, **sa3q4** records the reason that a household failed to harvest. Use `tabulate` to list the reasons households failed to harvest.

```{s}
	quietly tab sa3q4
```

Stata displays the reasons for failing to harvest as whole sentences in the output but each reason is stored in the data as integers and when we write code we have to use the integer. Find the integer code of a response using the data browser and find **sa3q4**. The cells still appear to show words for each reason but select a cell and notice that the text bar above the cell matrix displays an integer - this integer is what we write in our code. 

Sort the data on **sa3q4** to put the responses in ascending order so its easier to find a numbered response.

```{s}
	sort sa3q4
```

Identify the integer code for not harvesting because it was "not harvest season", "delayed harvest" and "other specify". 

Drop observations if they did not harvest because it was not harvest season, the harvest was delayed, and other non-specified reasons which should be encoded as 9, 10, and 11 respectively. We can combine these qualifiers into a single command using an "or" statement, note that stata reads the vertical line symbol “|” as an “or”.

```{s}
	quietly 	drop if 		sa3q4 == 9 | sa3q4 == 10 | sa3q4 == 11
```
	
The remaining households that did not harvest may have a missing harvest quantity and value. Make sure the remaining households that did not harvest have a 0 for the quantity and value of their harvest. Quantity is **sa3q6a1** and value is **sa3q18**.

```{s}
	replace			sa3q6a1 = 0 if sa3q6a1 == . & sa3q4 < 9
	replace			sa3q18  = 0 if sa3q18  == . & sa3q4 < 9
```

Many respondents in all three waves of the Nigeria survey gave the weights of their harvests in local units and not in standardized units. We ultimately want to produce a variable that is the maize yield measured in kilograms of maize per hectare and we will need to convert the non-standard units into kilograms. Rename **sa3q6a2** to **nscode**. Note that harvest units have been encoded in the data.

```{s}
	rename 			sa3q6a2 nscode
```

# Converting Harvest Weights to Kilograms

We will convert non-standard units into kilograms by merging the current dataset with "harvconv_wave_2.dta" which contains a numerical conversion factor to convert each crop and non-standard measurement to the equivalent measurement in kilograms. 

The non-standard units are a challenge to convert because some of the units are measured by volume such wheelbarrows and sacks. Sacks and wheelbarrows are not standard volumes either and they vary by the brand of the sack or wheelbarrow and possibly by region and the weight of a wheelbarrow of melons is not the same as the weight of a wheelbarrow of maize and so the conversion will be approximate and not perfect. 

Before merging keep in mind all crops of the same type when measured with the same units will share the same conversion factor. In matching more than one oberservation from the main dataset to one observation in the merging dataset the merge is called a many to one merge. Keep "ph_secta3.dta" open and merge "harvconv_wave_2.dta" on **cropcode** and **nscode** and specify the type of merge is m:1, many to one.

```{s}
 merge 			m:1 cropcode nscode using "$root/wave_2/raw/w2agnsconversion.dta"
```

After a merge command Stata automatically produces a variable called **_merge** that it is encoded as **_merge**==3 if an observation from the "master" (the main file secta3_harvestw2.dta) was matched to an observation from the "using" (the conversion file). **_merge**==1 if an observation from the master file was unable to be matched to an observation in the using, this means a crop is measured by a unit we do not have a conversion. And **_merge**==2 if an observation from the using file was not matched to the master, this means the using file contained a crop and a unit of measurement that is not present in the main data, which is a conversion we do not need. Drop the observations we don't need.

```{s}
	drop if			_merge == 2
```

Lets address the observations that are missing a conversion. A likely culprit for an unmatched observation is a missing **nscode** or **cropcode**. Check for missing **nscode** by asking stata to count the observations with missing **nscode**,(==.), and a **_merge**==1.

```{s}
	count if 		nscode==. & _merge == 1
```

Drop those observations that are missing an **nscode** because we cannot convert those observations without the unit.

```{s}
	drop if 		nscode == . & _merge == 1
```

An observation can go unmatched if the conversion file did not have a conversion for a unit in the master. Tabulate **nscode** for the unmatched observations to check if something was omitted.

```{s}
	tab 			nscode if _merge == 1
```

If an umatched observation is already in kilograms, or grams or a unit you know how to convert to kiligrams then we can keep those observations. We need to replace the **conversion** for those observations with the conversion factor. For example replace the missing conversion for kilograms to 1. **nscode** is encoded and we must sort the data on **nscode** and look up the code for kilograms in the data browser. But to save you time kilograms are encoded 1. 

```{s}
	replace			conversion = 1 if conversion == . & nscode==1
```

We drop an observation if the harvest unit cannot be converted. Note in Stata “!=” is equivalent to the statement “not equal to”.

```{s}
	drop if			_merge == 1 & nscode != 1
```

We can now drop the **_merge** variable.

```{s}
	drop 			_merge
```

Check for missing **conversion** factor.

```{s}
	count if		conversion == .
```

Generate **harv_kg** by multiplying the conversion factors with the nonstandard weights.

```{s}
	generate			harv_kg = sa3q6a1*conversion
```
	
Several types of maize varieties were grown and we want to make it easier by recoding them all as one type of maize. Sort **cropcode** and then look in the data browser to find the codes for the different types of maize. Note that all types of maize are encoded between 1080 and 1084 and generic maize is 1080. Replace all maize with 1080.

```{s}
	replace			cropcode = 1080 if cropcode > 1079 & cropcode < 1084
```

Make a maize harvest variable called **mz_hrv** for all the maize crop weights. All non-maize observations will be missing in the variable **mz_hrv**.

```{s}
	gen 			mz_hrv = harv_kg 	if 	cropcode == 1080
	lab var			mz_hrv "Quantity of maize harvested (kg)"
```

# Imputing Far Outliers

Imputation replaces missing data with an estimate from the existing data. We use Predictive Mean Matching (PMM) imputation. We set out the steps taken in PMM imputation to provide context for the impute commands in Stata. 

We estimate the missing data with a least squares regression. The variable with the missing observations is the dependent variable. For each missing observation we obtain an estimated observation. The estimate is matched to 5 non-missing observations in the dependent variable that are closest to the estimated value. One of the 5 close observations is randomly chosen to replace the missing observation. The process repeats multiple times until there is a set of estimated values of the missing observation. Replace the missing variable with the average of all estimates from all iterations. See Kilic, et al 2017 for more details on the process of imputation with household survey data.

`Summarize` **mz_hrv** for the mean, maximum, minimum and other statistics. 

```{s}
	sum				mz_hrv, detail
```

Compare the summary statistics to reliable crop yield data from the area of study and determine if our data appears at first glance to be reasonable in the context of the region we are studying. 

You may use your discretion in choosing how to identify outliers and be consistent to your identification throughout your data cleaning process. We consider an outlier to be an observation that is above 3 standard deviations above the mean. The stata code for 3 standard deviations above the mean is `r(p50)' + (3*`r(sd)') where `r(p50)' is the mean and `r(sd)' is the standard deviation and 3*`r(sd)' is 3 times the standard deviation. Replace observations that are outside of the 3 standard deviations as missing.

```{s}
replace			mz_hrv = .  	if 	mz_hrv > `r(p50)' + (3*`r(sd)')
```

`Mi` (multiple imputation) is the Stata command for imputing. Set the data structure as wide or long. Our data is wide because a unique observation is identified by a unique row.

```{s}
	quietly mi set 			wide 
```
Clear any time series settings you may have in place or else the time series will interfere with the linear regression we run later.

```{s}
	quietly mi xtset		, clear 	
```
	
Register **mz_hrv** as the variable we will be imputing.

```{s}
	quietly mi register		imputed mz_hrv 
```

Sort the data to ensure reproducibility. Sorting the data can be done at any stage before the actual imputation. Data is uniquely identified by **hhid** **plotid** **cropid**. 


```{s}
	sort			hhid plotid cropid 
```

And finally imputing. Since imputing is a process of estimation it is natural that we should specify the estimation similar to setting up a simple regression. Impute with the fertilizer variable as the dependent variables and state, the variable for the geographic state location of the observation, as the independent variable. 

Use predictive mean matching (pmm) to impute the data, the regression’s dependent variable is **mz_hrv** and the independent variable is **i.state** (a dummy for each state). Set option "force" to enable the regression to run even if an error occurs; "knn(#)" determines the number of non-missing **mz_hrv** observations to match to the estimate, for example we choose to match to the nearest 5 observations; "bootstrap" requests Stata sample the data with replacement and regress on the created random sample; "rseed(#)" specifies the random number seed used to create the sample. 
	
```{s}	
	quietly mi impute pmm mz_hrv i.state if cropcode == 1080, add(1) rseed(245780) noisily dots force knn(5) bootstrap
```

Declare the imputing to be over:

```{s}
	quietly mi 				unset	
```
	
Use `tabstat` to compare the imputed maize harvest variable (**mz_hrv_1_**) to the original maize harvest variable (**mz_hrv**). `tabstat` compares two or more variables on the parameters of our choice, for example we want to see the number of observations in each variable “n”, the mean, “mean”, and the minimum and the maximum, “min” and “max”.

```{s}
	quietly tabstat			mz_hrv mz_hrv_1_ if cropcode == 1080, by(mi_miss) ///
						statistics(n mean min max) columns(statistics) ///
						longstub format(%9.3g) 
```

If after imputation the data resembles the known distribution of maize yields in Nigeria then replace the original maize harvest (**mz_hrv**) with the imputed maize harvest (**mz_hrv_1**) and drop the imputed maize harvest. If the results are still not resembling known distributions then you can start by reducing the distribution you tolerate and replace more missing values based on the new outlier boundaries, then impute the missing data. We continue assuming we are satisfied with our first attempt.

```{s}
	replace			mz_hrv = mz_hrv_1_  if cropcode == 1080
	drop			mz_hrv_1_
```

Make an identifier variable **cropplot** that uniquely identifies a crop by the crop’s name, the plot it was grown on, and the household that grew it.  The Stata command `isid` checks a variable or list of variables uniquely identify our observations. Stata will not display a result after the `isid` command if the variables do uniquely identify our observations but will display an error if the variables do not uniquely our observations. 

```{s}
	isid			hhid plotid cropid
	sort			hhid plotid cropid
	egen			cropplot_id = group(hhid plotid cropid)
	lab var			cropplot_id "unique crop-plot identifier"
```

We also want to make an id variable to identify the plot by the household ID and the plot ID. There may be several crops planted on one plot so **plot_id** will not uniquely identify the observations in this dataset but it will be the variable we use to match other inputs that are at the plot level.

```{s}
	sort			hhid plotid 
	egen			plot_id = group(hhid plotid)
	lab var			plot_id "unique plot identifier"
```

Save the file we have been working on and save it in a seperate place to the orignal raw data.

```{s}
	save "$root/wave_2/refined/ph_secta3.dta", replace	
```




# Cleaning Land Area

This section also appears as it own chapter but is reproduced here because land area is necessary to construct yield.

Calculating yield requires using the weight of the harvest and the land area the harvest was grown on. We demonstrate how to generate a data set for plot sizes in hectares from the Nigeria General Household Survey. During survey work selected plots were measured with a handheld GPS. All plots were also have a measure of size given by the farmers. The GPS is more accurate than the self reported plot sizes. But we will attempt at first to use both measures in the end. The GPS measure was taken in meters, it is straightforward to convert to hectares. The self reported plot sizes are reported in multiple units you may or not recognize. Those can be converted straightforwardly with the conversion file. 

```{s}
use "$root/wave_2/raw/sect11a1_plantingw2.dta", clear
```

The variables have coded names that refer to the question in the survey. You can access the survey instrument on the World Bank website and look up the question to see exactly how the question was put to the respondents. In the data the labels tell us something about what the variable measures. `Describe` outputs all variables' labels along with data type and more technical information about howo the variable is stored in the file. 

We have used the `quietly` command to suppress stata from displaying output. You do not have to include the quietly command. We have included it to make the guide more user friendly and not filled with stata output.

```{s}
	quietly describe
```	

Each observation is a plot and plots are identified within a household by a plot id, and households are identified by a household ID. We can check if **hhid** and **plotid** uniquely identify the data with `Isid`, which will not return an output if the variables we suspect do uniquely identify the data and display an error if the data is not unique.

```{s}
	sort 			hhid plotid
	isid 			hhid plotid
```

We now inspect the self reported plot size variable, **s11aq4a**. 

`describe s11aq4a` to display the label in the data. The label is "FARMERS RECALL NUMBER". The recall number is the farmer's recollection of the size of their plot in their preferred unit. When in doubt about what a variable is measuring look at the documentation which tells you what question was asked to the farmer.

Rename the variable **s11aq4a** **plot_size_SR** and give it a clearer label.

```{s}
	rename 			s11aq4a plot_size_SR
	lab	var			plot_size_SR "self reported size of plot, not standardized"
```

Let's also rename the variable for the farmer's unit, **s11aq4b**. The label of the variable is "FARMERS UNIT".
	
```{s}
	rename 			s11aq4b plot_unit
	lab var			plot_unit "self reported unit of measure"
```

Now rename and label the variable of GPS plot areas, **s11aq4c**. 

```{s}
	rename			s11aq4c	plot_size_GPS
	lab var			plot_size_GPS 	"GPS plot size in sq. meters"
```

# Convert Plot Size to Hectares

We need to merge in a land conversion file to convert the self reported land areas and the GPS measures into hectares. The conversion file is organized by geographic zones because the units are slightly different in each zone. Each variable in the conversion file is a conversion factor to hectares for a unit of land area measurement. We will merge the conversion files on zones. The merge will be a many to one merge. The merge is called many to one merge or `m:1` when one observation from the "using" file, the conversion file in our case, is matched to more than one observation in the "master" file, the main file.

```{s}
	merge 			m:1 	zone using 	"$root/wave_2/raw/land-conversion.dta"
```
The variable **_merge** is made after a merge and assigns each observation a code if it was succesfully matched between the master and the using.

Hopefully everything in the master was matched. Not everything in the using needs to match. If an observation in the using does not match this means that there is a conversion factor in the conversion file we do not need. Keep the observations that matched and drop all the unmatched observations if the number of unmatcehd was very small. Drop the **_merge** command if you are satisfied. Go back to the merge and look for code errors if many observations did not match. Common code errors are the wrong matching criteria, the wrong merge options, the wrong file.

```{s}
	keep 			if 		_merge == 3
	drop 			_merge
```

Look at the the units the farmers used to measure their plots. They used heaps, ridges, stands, etc. 

```{s}

	quietly tab 			plot_unit
```

We are going to convert the units by multiplying the self reported size by a conversion factor. If plot unit is heaps then multiply **plot_size_SR** by **heapcon**. Do likewise for the other units.

Self reported plot unit is encoded in the data with numbers and not words as it appears in the tab command. We have written the unit code and can tell you the code for each unit. We found the code by `sort plot_unit`, then going to the data browser, selecting a cell in **plot_unit** variable, and seeing the number displayed in the bar at the top of the data browser window. 

```{s}
	gen 			plot_size_hec_SR = .
	lab var			plot_size_hec_SR 	"SR plot size converted to hectares"
```
Ridges are `plot_unit == 2`
```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR*ridgecon	if plot_unit == 2
```

Heaps are `plot_unit == 1`
```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR*heapcon	if plot_unit == 1
```
Stands are `plot_unit==3`
```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR*standcon	if plot_unit == 3
```
Plots are `plot_unit ==4`
```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR*plotcon	if plot_unit == 4
```
Acres are `plot_unit==5`
```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR*acrecon	if plot_unit == 5
```
Square meteres are `plot_unit==7`
```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR*sqmcon		if plot_unit == 7
```
Hectares are already in hectares so we don't need to convert them. The hectare code is `plot_unt == 6`

```{s}
	quietly replace 		plot_size_hec_SR = plot_size_SR			if plot_unit == 6
```

Most of the plots should now be in hectares but let's check for the missing ones. If they are missing and they have a unit we can convert then convert them. If they are not converted and they do not have a unit that does not appear in the conversion file then leave them missing. We should also replace any observations with "other unit", `plot_unit==8` and impute them later.

```{s}
	count			if plot_size_hec_SR == . 
	quietly replace  		plot_size_hec_SR = . if plot_unit == 8
```

We turn to the GPS measures. Check how many plots do not have a GPS.

```{s}
	count 			if plot_size_GPS == . 
```
Quite a few do not have a GPS measure in this file. We should not delete these observations but impute them later. 

Convert the GPS in square meters into hectares.

```{s}
	gen 			plot_size_hec_GPS = .
	lab	var			plot_size_hec_GPS "GPS measured area of plot in hectares"
	replace 		plot_size_hec_GPS = plot_size_GPS*sqmcon
```

Look again the number of plot sizes that were not converted. Make sure they did not fail convert and had a plot size in square meters. The ones we cannot convert we will impute later
```{s}
	count 			if plot_size_hec_GPS !=.
	count			if plot_size_hec_GPS == . 
```

How many observations have no self reported plot size and no GPS?

```{s}
	count	 		if plot_size_hec_SR != . & plot_size_hec_GPS != .
```
There are a lot of observations that lack both. This will prove a slight inconvenience because we intended to impute an estimate of the missing plot size variable, self reported and GPS, with the non-missing plot size variable. We obviously cannot do that if they are both missing. But we will find other ways to impute which we discuss in the dueness of course.

# Impute the Missing Plot Sizes

Self reported plot size and GPS plot size measure the same thing so if they are both reported perfectly then the two variables should be identical or very close at least. But this is not often the case. Farmers sometimes have difficulty accurately recalling the size of their plot. 

We can Check the correlation between self reported plot size and the GPS plot size with `pwcorr`.

```{s}
	pwcorr 			plot_size_hec_SR plot_size_hec_GPS
```

There is a low correlation between self reported plot size and GPS.

`pwcorr` has several options to change the range of values we want the correlation calculated on. For instance we might suspect that an incorretly large self reported plot size will have a lower correlation with the GPS plot size. Calculate the correlation of self reported and GPS of all observations within 3 standard deviations of the mean of GPS. Two steps are involved. First, `summarize plot_size_hec_GPS` in detail. Second, command `pwcorr` and an if statement to denote the range we want to consider.

The range command in full: `inrange(plot_size_hec_GPS,`r(p50)'-(3*`r(sd)'),`r(p50)'+(3*`r(sd)'))`

Here is a breakdown of how to get the range command as an option after `pwcorr`. 

`inrange()` signals that we want a specific range of observations to calculate the correlation on. It can be a range or a lower and upper bound, or just a lower bound or just an upper bound.

`inrange(plot_size_hec_GPS,` we want the range based on the values of "plot_size_hec_GPS".

`inrange(plot_size_hec_GPS,`r(p50)'-(3*`r(sd)')` the lower bound is three standard deviations, (3*`r(sd)'), below, -, the mean, `r(p50)'. 

`inrange(plot_size_hec_GPS,`r(p50)'-(3*`r(sd)'),`r(p50)'+(3*`r(sd)'))` the upper bound is three standard deviations, (3*`r(sd)'), above, +, the mean, `r(p50)'

```{s}
	sum 			plot_size_hec_GPS, detail
	pwcorr 			plot_size_hec_SR plot_size_hec_GPS if ///
						inrange(plot_size_hec_GPS,`r(p50)'-(3*`r(sd)'),`r(p50)'+(3*`r(sd)'))
```
The correlation turns out to be even lower when we exclude outliers. Clearly the correlation is sensitive to the boundaries so try another range. Set the range to only observations within three standard deviations of both GPS and self reported. Summarize all the variables first before using their measures of central tendency.

```{s}
	sum 			plot_size_hec_GPS, detail
	sum 			plot_size_hec_SR, detail
	pwcorr 			plot_size_hec_SR plot_size_hec_GPS if ///
						inrange(plot_size_hec_GPS,`r(p50)'-(3*`r(sd)'),`r(p50)'+(3*`r(sd)')) & ///
						inrange(plot_size_hec_SR,`r(p50)'-(3*`r(sd)'),`r(p50)'+(3*`r(sd)'))
```

The correlation is even lower.

Consider the observations we left out when we set the range. Examine larger plot sizes.

```{s}

		quietly tab				plot_size_hec_GPS 	if 	plot_size_hec_GPS > 2
```
There are few plots larger than 2 hectares.
```{s}

	quietly tab				plot_size_hec_GPS 	if 	plot_size_hec_GPS > 20
```{s}
There are none greater than 20 hectares. There are no unreasonably large plots.

Even so check the correlation at larger plot sizes.


```{s}
	sum 			plot_size_hec_GPS, detail
	pwcorr 			plot_size_hec_GPS plot_size_hec_SR 	if 	///
						plot_size_hec_GPS > 3 & !missing(plot_size_hec_GPS)
```

The correlation at larger plot sizes is higher than other ranges. But it is still low.

Compare the GPS and self reported variables side by side.
	
```{s}

	sum 			plot_size_hec_GPS
	sum 			plot_size_hec_SR
```

GPS tends to be smaller and more realistic. GPS is more accurate than self reported measures. GPS is more reliable than the self reported measures because at least we can say with confidence that the measurements were taken in the field by an enumerator with high precision instruments. We will not be using self reported because it has such a low correlation with the GPS measure which we are confident with.

Imputation replaces missing data with an estimate from the existing data. We use Predictive Mean Matching (PMM) imputation. We set out the steps taken in PMM imputation to provide context for the impute commands in Stata. 

We estimate the missing data with a least squares regression. The variable with the missing observations is the dependent variable. For each missing observation we obtain an estimated observation. The estimate is matched to 5 non-missing observations in the dependent variable that are closest to the estimated value. One of the 5 close observations is randomly chosen to replace the missing observation. The process repeats multiple times until there is a set of estimated values of the missing observation. Replace the missing variable with the average of all estimates from all iterations. See Kilic, et al 2017 for more details on the process of imputation with household survey data.

`Mi` (multiple imputation) is the Stata command for imputing. Set the data structure as wide or long. Our data is wide because a unique observation is identified by a unique row.

```{s}

	mi set 			wide 
```	
Clear any time series settings you may have in place or else the time series will interfere with the linear regression we run later.
```{s}

	mi xtset		, clear 
```
Register ***plot_size_hec_GPS*** as the variable we will be imputing.
	
```{s}

	mi register 	imputed plot_size_hec_GPS
```
Sort the data to ensure reproducibility. Sorting the data can be done at any stage before the actual imputation. Data is uniquely identified by ***hhid*** ***plotid*** ***cropid***. 

```{s}

	sort			hhid plotid, stable 
```
	
Use predictive mean matching (pmm) to impute the data, the regression’s dependent variable is **plot_size_hec_GPS** and the independent variable is **i.state** (a dummy for each state). Set option "force" to enable the regression to run even if an error occurs; "knn(#)" determines the number of non-missing **plot_size_hec_GPS** observations to match to the estimate, for example we choose to match to the nearest 5 observations; "bootstrap" requests Stata sample the data with replacement and regress on the created random sample; "rseed(#)" specifies the random number seed used to create the sample. 


```{s}
	quietly mi impute 		pmm plot_size_hec_GPS i.state, add(1) rseed(245780) noisily dots ///
						force knn(5) bootstrap
```
Declare the imputing to be over:

```{s}

	quietly mi unset
```
	
Use `tabstat` to compare the imputed plot size (**plot_size_hec_GPS_1_**) to the original plot size (**plot_size_hec_GPS**). The "tabstat" command compares two or more variables on the parameters of our choice, for example we want to see the number of observations in each variable, “n”, the mean, “mean”, and the minimum and the maximum, “min” and “max”. `Tabstat` is a versatile command and the researcher can choose to report the statistics of their choice. 

```{s}
	quietly tabstat 		plot_size_hec_GPS plot_size_hec_SR plot_size_hec_GPS_1_, ///
						by(mi_miss) statistics(n mean min max) columns(statistics) ///
						longstub format(%9.3g)
```

Do the changes look reasonable? If they are reasonable then we can replace the missing values with the imputed values.

```{s}
	replace			plot_size_hec_GPS = plot_size_hec_GPS_1_
```

Are there any more missing plot sizes? 

```{s}
count  				 if plot_size_hec_GPS == .
```
Rename our main variable.
```{s}
	rename			plot_size_hec_GPS_1_ plotsize
	lab	var			plotsize	"plot size (ha)"
```

```{s}
	save "$root/wave_2/refined/sect11a1_plantingw2.dta", replace	
```

# Maize Yield

 Now open "secta3_harvestw2.dta" and merge the crop data with the plot data. We want to use "secta3_harvestw2.dta" as the master file because all crops were grown on plots but not all plots were used to grow crops. 

```{s}
	use				"$root/wave_2/refined/ph_secta3.dta", clear 
```
	
We made an id variable **cropplot_id** when working on "sect3a_harvestw2.dta" confirm that it uniquely identifies each observation with the `isid` command. Recall that when a variable uniquely identifies each observation `isid` will not display a result and when a variable fails to uniquely identify the observations `isid` will display an error.

```{s}
	isid			cropplot_id
```
	
Merge in plot size data, "sect11a1_plantingw2.dta", and merge on ***hhid*** and ***plotid***. Multiple crops can be grown on one plot and multiple crops may be matched to the same plot, set the matching option to many to one (m:1).

```{s}
	merge 			m:1 hhid plotid using "$root/wave_2/refined/sect11a1_plantingw2.dta"
```
	
Drop observations that did not match. Observations that did not match are plots that we cannot match to a crop or crops we cannot match to a plot and the only way to identify where a crop was grown or what crop was grown on a plot is the `merge` command we just executed so we cannot do much more. Recall all successful matches have **_merge**=3. Note “!=” is equivalent to a "not equal" statement so let's use != to drop all observations not equal to 3.

```{s}
	drop			if _merge != 3
```
	
The data is currently at the crop level, `collapse` the data to the plot level. Before we collapse note currently there may be multiple entries for a single plot because the same plot may have matched with multiple crops and we want to condense multiple crop entries into a single entry that summarizes all the crop data for one plot. So we have to decide how to agglomerate multiple crops, in this case adding them together is best option. So we write the option (Sum) after "collapse" to get the total weight of maize harvested from the plot. Take the maximum value of the plot size, plot duplicates have the same size. 

```{s}
	quietly collapse (sum)	 mz_hrv  (max) cropid cropcode plot_size_hec_GPS, by(hhid plotid zone state lga sector ea)
```

Generate a variable for the area of land maize was grown on.

```{s}
	gen			mz_lnd = plot_size_hec_GPS	if mz_hrv != .
```

Construct maize yield (kg/ha).

```{s}
	gen			mz_yld = mz_hrv / mz_lnd, after(mz_hrv)
	lab var			mz_yld	"maize yield (kg/ha)"
```

We want the data set to only have the variables we are interested in using so we should drop the ones we are not using. There are more variables we want to drop so we can use `keep` to keep the ones we want and drop everything else.

```{s}
	keep 		zone state lga sector ea hhid plotid cropid cropcode mz_hrv
```
					
Save the file.

```{s}
	save "$root/wave_2/refined/secta3_harvestw2.dta", replace	
```

	
# Citations

Kilic, T., Zezza, A., Carletto, C., & Savastano, S. (2017). Missing (ness) in action: selectivity bias in GPS-based land area measurements. World Development, 92, 143-157.

