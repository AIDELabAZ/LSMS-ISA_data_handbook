% Generating Crop Output from the Nigeria General Household Survey, Panel 2012-2013, Wave 2
% Emil Kee-Tui 
% `s c(current_date)`

This is a guide to generating crop output variables including a maize yield variable (kilograms of maize per hectare) from the Nigeria General Household Survey, Panel 2012-2013, Wave 2 (Survey ID Number: NGA_2012_GHSP-W2_v02_M). If you want to see how the questions were actually given to respondents you can refer to page 13 of "PH_W2_Agriculture_Questionnaire_Final.pdf" which you can find in the "/questionnaire" section of the LSMS-ISA data handbook folder, "\git\lsms-isa_data_handbook\questionnaires\PH_W2_Agriculture_Questionnaire_Final.pdf".

The primary raw data file for this excercise is "secta3_harvestw2.dta".

```{s}

use "$root/wave_2/raw/NGA_2012_GHSP-W2_v02_M_STATA/Post Harvest Wave 2/Agriculture/secta3_harvestw2.dta", clear 

```

This data was collected after the main harvest and is at the crop level, meaning that each observation represents a single crop. Open the ***Data Editor (browser)***; this can be accessed by the ***Data*** tab in the stata menu, then the ***Data Editor*** option. Each observation is a row in the spreadsheet, and each observation represents data on a particular crop. Respondents were asked questions about each crop they planted, such as how much they harvested, if it was sold how much it was worth, the plot it was grown on, etc. 

***Note: We have used the `quietly` command in our code to suppress stata from displaying output. Omit `quietly` when you build your own code so you can see the output. We have included `quietly` to make the guide more user friendly and not filled with stata output.***

Maize will be the main crop we are interested in because it is one of the most widely cultivated crops. `tab` will display the different types of crops.

```{s}
quietly tabulate cropcode
```

The names of the crops are displayed as words in the `tab` output table but they are encoded as integers in the data. Encoding is a process where a number in the data represents a word, a name, or a phrase. Maize is encoded as 1080 in **cropcode**.

We want to restrict our observations to a single harvest season. Some households might not have completed their harvest when the enumerators conducted their surveys, harvest delays are not unusual and in the real world something sometimes comes up. People might not have harvest because of a crop failure. We do not want to remove observations because they had a crop failure. Crop failures will be noted by 0 kilograms of crop output. But we will drop those households that did not harvest because it was not harvest season or they delayed their harvest and will harvest in another season. We can identify households that did not harvest this season for a reason besides crop failure using **sa3q3**, which records the response to the question "Have you harvested any of the following crops since the last interview?" You could not tell what **sa3q3** refered to by its name alone. The variable is coded to be matched to the questionnaire which was administered in the data collection.  But to make the variable clearer for ourselves rename **sa3q3** to **harvest**:

```{s}
	quietly rename sa3q3 harvest
```

Note, **sa3q4** records the reason that a household failed to harvest. Use `tabulate` to list the reasons households failed to harvest.

```{s}
	quietly tab sa3q4
```

Stata displays the reasons for failing to harvest as whole sentences in the output but each reason is stored in the data as integers because it is encoded. When we write code to refer to specific value in the variable **sa3q4** we have to use the integer. Find the integer code of a response by looking up **sa3q4** in the Data Editor (browser). Select a cell in the **sa3q4** column and notice that the text bar above the cell matrix displays an integer - this integer is what we write in our code to refer to that value, we do not write the words that number represents. Sort the data on **sa3q4** to put the responses in ascending order so its easier to find a response.

```{s}
	sort sa3q4
```

Refering to **sa3q4** identify the integer code for not harvesting because it was "not harvest season", "delayed harvest" and "other specify". 

Drop observations if they did not harvest because it was not harvest season, the harvest was delayed, and other non-specified reasons; those codes are 9, 10, and 11 respectively. We can use a single command with qualifiers to drop all observations where **sa3q4** is equal to 9 or 10 or 11. ***Note: in stata the vertical line symbol “|” represent an “or” logic statement.***

```{s}
	quietly 	drop if 		sa3q4 == 9 | sa3q4 == 10 | sa3q4 == 11
```
	
The remaining households that did not harvest should also have a missing or zero harvest quantity and value. Make sure the remaining households that did not harvest have a zero value for the quantity harvested, **sa3q6a1**, and the value of harvest, **sa3q18**.

```{s}
	quietly replace			sa3q6a1 = 0 if sa3q6a1 == . & sa3q4 < 9
	quietly replace			sa3q18  = 0 if sa3q18  == . & sa3q4 < 9
```

Many respondents in the Nigeria survey gave the weights of their harvests in local units and not in standardized units. We want to produce a variable that is the maize yield measured in kilograms of maize per hectare and we will need to convert the non-standard units into kilograms. Rename **sa3q6a2** which is the response to the question "HOW MUCH DID YOU HARVEST SINCE THE LAST INTERVIEW?(PRODUCTION UNIT CODE)" to **nscode**. ***Note: **sa3q6a2** has been encoded in the data.***

```{s}
	quietly rename 			sa3q6a2 nscode
```

# Converting Harvest Weights to Kilograms

The data set "harvconv_wave_2.dta" is a conversion file, it contains conversion factors for the many non-standard weight units in our main dataset. "harvconv_wave_2.dta" will allow us to convert a weight in non-standard units into an equivalent weight in kilograms.

The non-standard units are a challenge to convert because some of the units are volumes such wheelbarrows and sacks. Sacks and wheelbarrows are not standard volumes either and they vary by the brand of the sack or wheelbarrow and possibly by region. Another problem with converting volumes to weights is the weight of a wheelbarrow of melons is not the same as the weight of a wheelbarrow of maize. Finally how much maize would have to fill a wheelbarrow before the farmer had what they called a wheelbarrow of maize? For these reasons the conversion will be approximate and not perfect. 

We will merge the conversion file on **cropcode** and **nscode**. The merge will be a many to one merge. The merge is called a many to one merge or `m:1` when one observation from the "using" file, the conversion file in our case, is matched to more than one observation in the "master" file, the main file. All crops of the same type when measured with the same units will share the same conversion factor, so one conversion factor from the "using" file will be matched to "many" observations in the "master" file. 

```{s}
 merge 			m:1 cropcode nscode using "$root/wave_2/raw/NGA_2012_GHSP-W2_v02_M_STATA/w2agnsconversion.dta"
```

After a merge command Stata automatically produces a variable called **_merge**. **_merge** is encoded as **_merge**==3 if an observation from the "master" (the main file secta3_harvestw2.dta) was matched to an observation from the "using" (the conversion file); **_merge**==1 if an observation from the master file was unable to be matched to an observation in the using, this means a crop is measured by a unit we do not have a conversion factor for; and **_merge**==2 if an observation from the using file was not matched to the master, this means the using file contained a crop and a unit of measurement that is not present in the main data, which is a conversion we do not need. Drop the observations we don't need.

```{s}
	quietly drop if			_merge == 2
```

Lets address the observations from the master that are missing a conversion. A likely culprit for an unmatched observation is an observation is missing an **nscode** or a **cropcode**. Check for missing **nscode** by asking stata to count the missing observations: `**nscode**==. & *_merge**==1`.

```{s}
	quietly count if 		nscode==. & _merge == 1
```

Drop those observations that are missing an **nscode** because we cannot convert those observations without the unit.

```{s}
	quietly drop if 		nscode == . & _merge == 1
```

An observation can go unmatched in the master if the conversion file did not have a conversion for a unit in the master. Tabulate the units which were not matched from the master.

```{s}
	quietly tab 			nscode if _merge == 1
```

If an observation is already in kilograms, or grams or a unit we are familiar with then we can manually input a conversion factor. We need to replace the **conversion** for those observations that are missing a conversion factor and have a known unit. For example replace the missing conversion for kilograms to 1, the unit is already in kilograms so we don't need to change anything. **nscode** is encoded so we must sort the data on **nscode** and look up the code for kilograms in the data browser. But to save you time kilograms is encoded with 1. 

```{s}
	quietly replace			conversion = 1 if conversion == . & nscode==1
```

The conversion from grams to kilograms is to multiply the grams by 0.001. Grams are encoded as **nscode**== 2. 

```{s}
	quietly replace			conversion = 0.001 if conversion == . & nscode==2
```

Litres was a unit which was not converted. One litre of water is equivalent to one kilogram. We might get away with assuming that liquids like palm oil are close to the density of water, but we cannot convert a solid crop such as bananas from litres to kilograms. First, we would have to have a clear idea about what a litre of bananas is. Litres are encoded as **nscode**==3. 

```{s}
	tab				cropcode 	if conversion == . & nscode==3
```

Oil from a palm tree, **cropcode**== 3180, is the only substance which is a liquid and was measured in litres and did not get a conversion factor.

```{s}
	quietly replace			conversion = 1 if conversion == . & nscode==3
```

We drop an observation if the harvest unit cannot be converted. ***Note in Stata “!=” is equivalent to the statement “not equal to”.***

```{s}
	quietly drop if			_merge == 1 & conversion == .
```

We can now drop the **_merge** variable.

```{s}
	quietly drop 			_merge
```

Check for missing **conversion** factor.

```{s}
	count if		conversion == .
```

There should not be any observations missing a conversion.  

Now we can generate a variable measuring the weight of the crop harvest in kilograms. Generate **harv_kg** by multiplying the conversion factors with the harvest quantity.

```{s}
	quietly generate			harv_kg = sa3q6a1*conversion
	label var 					harv_kg "Quantity of harvest (kg)"
```
	
Maize is the main crop we are interested in measuring. Several types of maize varieties were grown and we want to make it easy to work with all of them at once. So we are recoding them all as one type of maize. Sort **cropcode** and then look in the data browser to find the codes for the different types of maize. All types of maize are have codes between 1080 and 1084 and generic maize is 1080. Replace all maize with 1080.

```{s}
	quietly replace			cropcode = 1080 if cropcode > 1079 & cropcode < 1084
```

Make a maize harvest variable called **mz_hrv** for all the maize crop weights. All non-maize observations will be missing in the variable **mz_hrv**. Also make a variable for damaged maize observations. An observation was damaged if the farmer grew maize but they did not harvest any amount of maize.

```{s}
	quietly gen 			mz_hrv = harv_kg 	if 	cropcode == 1080
	quietly lab var			mz_hrv "Quantity of maize harvested (kg)"
	quietly gen				mz_damaged = 1		if  cropcode == 1080 & mz_hrv == 0
```

# Imputing Far Outliers

`Summarize` **mz_hrv** for the mean, maximum, minimum and other statistics. 

```{s}
	sum				mz_hrv, detail
```

Compare the summary statistics to reliable crop yield data from the area of study and determine if our data appears at first glance to be reasonable in the context of the region we are studying. We discovered that the mean maize harvest data we have in our data was much higher than the mean maize harvest from previous studies. We suspect that large unrealiable outliers are driving the high mean, we want to impute the far outlier observations that we think are unrealiable.

Imputation replaces missing data with an estimate of the missing data calculated from the data we do have. We use a particular type of imputing called Predictive Mean Matching (PMM) imputation. We set out the steps taken in PMM imputation to provide context for the impute commands in stata. 

We estimate a linear regression where the dependent variable is the variable with the missing values and the independent variables are predictors of the dependent variable. A variable which predicts crop outputs, for example, is geographic location because the crop outputs of neighbors are likely correlated. From the regression we get an estimate of the dependent variable, the estimated dependent variable includes linear estimates of the missing observations. Then, the estimate for each missing value is matched to the five closest non-missing observations in the dependent variable. One of the five non-missing observations is randomly chosen and temporarily stored. The estimating, matching, and randomization process repeats multiple times until there is a set of stored estimated values for each missing observation. The missing values are replaced with the average value of the elements of the set of estimates. See Kilic, et al 2017 for more details on the process of imputation with household survey data.

As a first step we must decide what an outlier observation is. You may use your discretion in choosing how to identify outliers and be consistent to your identification throughout your data cleaning process. We consider an outlier to be an observation that is above three standard deviations above the mean. The stata code for three standard deviations above the mean is `r(p50)' + (3*`r(sd)') where `r(p50)' is the mean and `r(sd)' is the standard deviation and three*`r(sd)' is three times the standard deviation. Replace observations that are outside of the three standard deviations as missing.

```{s}
	quietly 	replace			mz_hrv = .  	if 	mz_hrv > `r(p50)' + (3*`r(sd)')
```

Having made some of the data missing the steps for imputing **mz_hrv** in stata are as follows:

`Mi` (multiple imputation) is the Stata command for imputing. Set the data structure as wide or long. Our data is wide because a unique observation is identified by a unique row.

```{s}
	quietly mi set 			wide 
```

Clear any time series settings you may have in place or else the time series will interfere with the cross-sectional linear regression we run later.

```{s}
	quietly mi xtset		, clear 	
```
	
Register **mz_hrv** as the variable we will be imputing.

```{s}
	quietly mi register		imputed mz_hrv 
```

Sort the data to ensure reproducibility. Sorting the data can be done at any stage before the actual imputation. Data is uniquely identified by **hhid** **plotid** **cropid**. 

```{s}
	sort			hhid plotid cropid 
```

And finally imputing with predictive mean matching (pmm). Since imputing is a process of estimation it is natural that we should specify the estimation similar to setting up a linear regression. Impute with **mz_hrv** as the dependent variable and **i.state**, an indicator variable for each geographic state, as the independent variable. Set option "force" to enable the regression to run even if an error occurs; "knn(#)" determines the number of non-missing **mz_hrv** observations to match to the estimate, for example we choose to match to the nearest five observations; "bootstrap" requests stata sample the data with replacement and regress on the created random sample; "rseed(#)" specifies the random number seed used to create the bootstrap sample. 
	
```{s}	
	quietly mi impute pmm mz_hrv i.state if cropcode == 1080, add(1) rseed(245780) noisily dots force knn(5) bootstrap
```

Declare the imputing to be over:

```{s}
	quietly mi 				unset	
```
	
Use `tabstat` to compare the imputed maize harvest variable (**mz_hrv_1_**) to the original maize harvest variable (**mz_hrv**). `tabstat` compares two or more variables on the parameters of our choice, for example: we want to see the number of observations in each variable, “n”; the mean, “mean”; and the minimum and the maximum, “min” and “max”.

```{s}
	quietly tabstat			mz_hrv mz_hrv_1_ if cropcode == 1080, by(mi_miss) statistics(n mean min max) columns(statistics) longstub format(%9.3g) 
```

If after imputation the data is a closer resemblance to the known distribution of maize yields in Nigeria then replace the original maize harvest (**mz_hrv**) with the imputed maize harvest (**mz_hrv_1**) and drop the imputed maize harvest. If the results are still don't resemble known distributions then you can re-examine the outliers again. Replace the outliers with missing if the outliers are still too high, and repeat the imputation steps for the new missing outliers. We can continue replacing with missing and imputing as long as we believe the outliers are unreliable. But we move on now in the guide assuming we have replaced the unreliable observations with imputations.

```{s}
	quietly replace			mz_hrv = mz_hrv_1_  if cropcode == 1080
	quietly drop			mz_hrv_1_
```

# Crop Value

The variable **sa3q18** records the Naira value of crops sold. We will convert the Naira value into real 2010 US dollars. Converting the Naira value to USD allows us to compare the Nigerian data with the other countries and converting the value to real USD allows us to compare the value of the 2012-2013 crop output to crop output from other waves.

We rename the Naira value variable with a name that is easy to associate with harvest value.
```{s}
	quietly gen 			vl_hrv = sa3q18
```

To convert Naira to USD we are going to divide the Naira observations by the real Naira to USD rates available from the World Bank. In 2012-2013, the real exchange rate of Naira to USD was 190.4143545 Naira to 1 USD.

```{s}
	quietly replace			vl_hrv = vl_hrv/190.4143545
	quietly lab var			vl_hrv 	"total value of harvest in 2010 USD"
```

# Imputing Crop Value

Summarize in detail the distribution of **vl_hrv**.

```{s}
	sum				vl_hrv, detail
```

The max, 13,654.43 is much larger than the mean, 105, and median, 226. The max is so large it seems unreliable. We will want to remove the extreme values in the variable. A value that falls outside of three standard deviations of the median is considered to be an extremely high value. The extremely high values relative to the rest of the data is likely due to a mistake in recall or recording. We will replace those high values with missing then we will imput the missing values.

```{s}
	replace			vl_hrv = . if vl_hrv > `r(p50)'+(3*`r(sd)')
```

We replaced 111 values and the max is now 1,054, which is a much more reasonable harvest value given the context. We can now impute the missing observations.

Set the data structure as wide or long. Our data is wide because a unique observation is identified by a unique row.

```{s}
	quietly 		mi set 			wide 
```
Clear any time series settings you may have in place or else the time series will interfere with the linear regression we run later.

```{s}
	quietly mi xtset		, clear
```

Register **vl_hrv** as the variable we will be imputing.

```{s}
	quietly mi register		imputed vl_hrv
```

Sort the data to ensure reproducibility. Sorting the data can be done at any stage before the actual imputation. Data is uniquely identified by **hhid** **plotid** **cropid**. 

```{s}
	quietly sort			hhid plotid cropid, stable
```

And finally imputing with predictive mean matching (pmm). Since imputing is a process of estimation it is natural that we should specify the estimation similar to setting up a linear regression. Impute with **vl_hrv** as the dependent variable and **i.state**, an indicator variable for each geographic state, as the independent variable. Set option "force" to enable the regression to run even if an error occurs; "knn(#)" determines the number of non-missing **vl_hrv** observations to match to the estimate, for example we choose to match to the nearest five observations; "bootstrap" requests stata sample the data with replacement and regress on the created random sample; "rseed(#)" specifies the random number seed used to create the bootstrap sample. 

```{s}
	quietly mi impute 		pmm vl_hrv i.state i.cropid, add(1) rseed(245780) noisily dots force knn(5) bootstrap
```

Declare the imputing to be over:

```{s}
	quietly mi 				unset	
```

Use `tabstat` to compare the imputed maize harvest variable (**vl_hrv_1_**) to the original maize harvest variable (**vl_hrv**). `tabstat` compares two or more variables on the parameters of our choice, for example: we want to see the number of observations in each variable, “n”; the mean, “mean”; and the minimum and the maximum, “min” and “max”.

```{s}
	quietly tabstat			vl_hrv vl_hrv_1_, by(mi_miss) statistics(n mean min max) columns(statistics) longstub format(%9.3g) 
```

If after imputation the data is a closer resemblance to the known distribution of harvest values in Nigeria then replace **vl_hrv** with the imputed value of harvest values **vl_hrv_1** and drop the imputed harvest value. If the results still don't resemble known distributions then you can re-examine the outliers again. Replace the outliers with missing if the outliers are still too high, and repeat the imputation steps for the new missing outliers. We can continue replacing with missing and imputing as long as we believe the outliers are unreliable. But we move on now in the guide assuming we have replaced the unreliable observations with imputations.

```{s}
	quietly replace			vl_hrv = vl_hrv_1_
	quietly drop			vl_hrv_1_
```

We will also make a maize harvest value variable.

```{s}
	quietly gen 			mz_vl = vl_hrv if mz_hrv != . | mz_hrv != 0
```

Make an identifier variable **cropplot** that uniquely identifies a crop by the crop’s name, the plot it was grown on, and the household that grew it. The command `isid` checks a variable or list of variables uniquely identifies all observations. Stata will not display any output after the `isid` command if the variables do uniquely identify our observations. Stata will display an error if the variables do not uniquely our observations. 

```{s}
	isid			hhid plotid cropid
	sort			hhid plotid cropid
	egen			cropplot_id = group(hhid plotid cropid)
	lab var			cropplot_id "unique crop-plot identifier"
```

We also want to make an id variable to identify the plot by the household ID and the plot ID. There may be several crops planted on one plot so **plot_id** will not uniquely identify the observations in this dataset but it will be the variable we use to match other plot level inputs to the crop outout at the plot level.

```{s}
	sort			hhid plotid 
	egen			plot_id = group(hhid plotid)
	lab var			plot_id "unique plot identifier"
```

Keep all the variables we need and drop the extra variables we will not use later.

```{s}
	keep zone state lga sector ea hhid plotid plot_id cropplot_id mz_vl harv_kg vl_hrv mz_hrv mz_damaged
```

Save the file in our clean data folder.

```{s}
	save "$root/wave_2/refined/ph_secta3.dta", replace	
```
